{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "L'obbiettivo del progetto è costruire un circuito quantistico per la compressione e ricostruzione di uno stato a diversi tassi di compressione. Lo stato iniziale a n qubit, viene manipolato da un circuito 2-locale (RealAmplitudes) in cui le rotazioni sono parametri del sistema, da ottimizzare in modo che all'uscita del circuito si trovi una rappresentazione codificata dello stato iniziale in cui venga mantenuta quanta più informazione possibile di esso. Data la natura degli stati e del circuito quantistici, non è possibile addestrare i parametri come in un autoencoder classico. La funzione costo viene ricavata attraverso un ulteriore circuito quantistico detto swap test, che presenta un output classico. L'ottimizazione avviene attraverso un algoritmo classico: COBYLA(Constrained Optimization by Linear Approximation). Si tratta di un metodo iterativo per l'ottimizzazione vincolata senza l'uso di derivate, in modo da evitare la delicata operazione di backpropagation attraverso il circuito quantistico. Vengono prodotte heatmap al fine di ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sezione 1 Introduzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sez 1.1 Modello del circuito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/setting.png\" alt=\"Alt Text\" width=\"1000\">\n",
    "    <p><em>Figure 1: lo stato di input è definito sullo spazio latente A e il trash space B. Il reference space (B') e il qubit ausiliario verranno usati nel circuito di SWAP TEST Rif. [2]</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compressione degli stati è realizzata mediante un circuito che opera su $n$ qubit che codificano lo stato originale $|\\psi_{AB}\\rangle$ , che verranno ridotti a $m$ qubit; i restanti $n-m$ qubit costituiscono il Trash Space, che sarà fondamentale per la misura della funzione costo.\n",
    "Gli stati su cui si andrà a operare sono $|\\Psi\\rangle=|\\psi_{AB}\\rangle\\otimes|a_{B'}\\rangle$ ovvero lo stato da comprimere e $|a_{B'}\\rangle=|0\\rangle^{\\otimes m}$, usato come reference per una operazione di misura detta swap test.\n",
    "\n",
    "Considerando il circuito encoder come un generico operatore unitario $U(\\theta_i)_{AB}$, il decoder è il corrispondente hermitiano coniugato $U(\\theta_i)^\\dagger_{AB'}$, con la differenza che il decoder agisce sullo spazio latente (cioè quello dello stato compresso) e sul reference space (quello dello stato di reference $a_{B'}$), che sostituisce i qubit scartati dall'encoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/schema1.png\" alt=\"Alt Text\" width=\"600\">\n",
    "    <p><em>Figure 2: Struttura del circuito. Rif. [2]</em></p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Loss più naturale per questo learner sarebbe la fedeltà tra lo stato originale e quello ricostruito $\\mathcal{L}_1= F(|\\psi_{AB}\\rangle,\\rho^{out})= \\langle \\psi_{AB} | \\rho^{out} | \\psi_{AB} \\rangle $ ,\n",
    "dove $\\rho^{out}= U(\\theta_i)^\\dagger_{AB'} Tr_{B}\\big[U(\\theta_i)_{AB} |\\Psi\\rangle\\langle\\Psi| U(\\theta_i)^\\dagger_{AB} \\big] U(\\theta_i)_{AB'} $, nella espressione precedente con A si intende il latent space,  B indica il trash space e B' il reference space, il significato dell'espressione è dunque applicare l'encoder, che agisce su A e B, rimuovere il trash con la traccia su B e ricostruire con il decoder, che agisce su A e su B'.\n",
    "Sfortunatamente siccome nel caso più generale lo stato originale non sarà più accessibile dopo la ricostruzione e non è possibile produrne una copia prima dell'encoding si deve trovare un'alternativa. Se consideriamo l'intero sistema possiamo trovare un modo, usando semplicemente le proprietà del prodotto scalare, siccome per stati puri $F(|\\chi\\rangle,|\\phi\\rangle)=|\\langle\\phi|\\chi\\rangle|^2$:\n",
    "\n",
    "\\begin{array}{ll}\n",
    "F(|\\psi_{AB}\\rangle\\otimes|a_{B'}\\rangle,U(\\theta_i)^\\dagger_{AB}V_{BB'}U(\\theta_i)_{AB}|\\psi_{AB}\\rangle\\otimes|a_{B'}\\rangle)=\\\\ \\\\\n",
    "=F(U(\\theta_i)_{AB}|\\psi_{AB}\\rangle\\otimes|a_{B'}\\rangle,V_{BB'}U(\\theta_i)_{AB}|\\psi_{AB}\\rangle\\otimes|a_{B'}\\rangle)=\\\\ \\\\\n",
    "=F(|\\psi'_{AB}\\rangle\\otimes|a_{B'}\\rangle,|\\psi'_{AB'}\\rangle\\otimes|a_{B}\\rangle)\n",
    "\\end{array}\n",
    "\n",
    "dove $V_{BB'}$ è l'operatore che scambia i sistemi B e B' e $|\\psi'_{AB}\\rangle=U(\\theta_i)_{AB}|\\psi_{AB}\\rangle$, nel contesto del sistema che comprende A, B e B' si scambiano reference e trash per effettuare la ricostruzione.  \n",
    "A questo punto se si prende la traccia nel sistema B', cioè il trash space, si ritorna alla $\\mathcal{L}_1$, se invece si traccia su A e B, quindi lo spazio latente e il reference space,  rimane $\\mathcal{L}_2=F(|a_{B'}\\rangle, \\rho'_{B'} )$, cioè la fedeltà tra il reference state e il trash state $\\rho'_{B'}=Tr_{AB}\\big[|\\psi'_{AB'}a_{B}\\rangle\\langle\\psi'_{AB'}a_{B}|\\big] $.\n",
    "Un altro vantaggio di questa strategia è che l'unica operazione richiesta per misurare la Loss coinvolge solo trash state e reference state, senza necessità di ricostruire lo stato in fase di apprendimento, quindi con minore probabilità di errori nel corso dell'esecuzione.\n",
    "Il principale inconveniente di questa soluzione è che $\\mathcal{L}_2 \\geq \\mathcal{L}_1$, quindi è possibile che la performance che viene effettivamente misurata durante il learning sia sovrastimata, tuttavia nel momento in cui una delle due è massima lo è anche l'altra, in quanto gli stati del sistema complessivo ABB' sono identici, dunque anche tutti gli stati dei sottosistemi lo saranno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sez1.2 SWAP TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/schema_SWAPTEST.png\" alt=\"Alt Text\" width=\"1000\">\n",
    "    <p><em>Figure 3: circuito SWAP TEST. Rif [2]</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procedura che consente di misurare la Loss consta di una sequenza di entanglement e misura in base computazionale, si inizia con due stati da comparare, che chiameremo genericamente $|\\psi\\rangle$ e $|\\phi\\rangle$ e un qubit ancella in $|0\\rangle$ oggetto della misura. Si agisce con una porta H sulla ancella, poi la si usa come qubit di controllo in una porta CSWAP su due qubit corrispondenti di $|\\psi\\rangle$ e $|\\phi\\rangle$, ripetendo l'operazione fino a scambiare del tutto i due stati, si opera nuovamente con H sull'ancella e infine si misura la medesima in base computazionale. Il risultato di tale procedura è il seguente:\n",
    "\n",
    "\\begin{array}{ll}\n",
    "|0\\rangle \\otimes |\\psi\\rangle \\otimes |\\phi\\rangle \\rightarrow \\frac{1}{\\sqrt{2}}[|0\\rangle+|1\\rangle]\\otimes |\\psi\\rangle \\otimes |\\phi\\rangle =\\\\\n",
    "\\frac{1}{\\sqrt{2}}[|0\\rangle \\otimes |\\psi\\rangle \\otimes |\\phi\\rangle+|1\\rangle \\otimes |\\psi\\rangle \\otimes |\\phi\\rangle]\\rightarrow \\\\\n",
    "\\frac{1}{\\sqrt{2}}[|0\\rangle \\otimes |\\psi\\rangle \\otimes |\\phi\\rangle+|1\\rangle \\otimes |\\phi\\rangle \\otimes |\\psi\\rangle]\\rightarrow\\\\\n",
    "\\frac{1}{2}[|0\\rangle|\\psi\\rangle|\\phi\\rangle+|1\\rangle|\\psi\\rangle|\\phi\\rangle+|0\\rangle|\\phi\\rangle|\\psi\\rangle-|1\\rangle|\\phi\\rangle|\\psi\\rangle]=\\\\\n",
    "\\frac{1}{2}|0\\rangle[|\\psi\\rangle|\\phi\\rangle+|\\phi\\rangle|\\psi\\rangle]+\\frac{1}{2}|1\\rangle[|\\psi\\rangle|\\phi\\rangle-|\\phi\\rangle|\\psi\\rangle]\n",
    "\\end{array}\n",
    "Ora, la probabilità di misurare $0$ è\n",
    "\\begin{array}{ll}\n",
    "\\frac{1}{4}\\big[ \\langle \\psi \\phi|+\\langle \\phi \\psi|\\big]\\big[ |\\psi\\phi\\rangle+|\\phi\\psi\\rangle \\big] =\n",
    "\\frac{1}{2}+\\langle \\psi \\phi|\\phi\\psi\\rangle\\langle \\phi \\psi|\\psi\\phi\\rangle=\\\\\n",
    "\\frac{1}{2}+\\big|\\langle \\psi \\phi|\\phi\\psi\\rangle\\big|^2=\\frac{1}{2}+\\frac{1}{2}F(|\\psi\\rangle, |\\phi\\rangle)\n",
    "\\end{array}\n",
    "\n",
    "dunque misurando ripetutamente lo stesso circuito possiamo ottenere una stima di questa probabilità come frequenza relativa degli zeri su tutti i tentativi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sezione 2 Implementazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per implementare il circuito di cui sopra si è usato Qiskit, una libreria Python per la programmazione di circuiti quantistici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, Aer, transpile, assemble\n",
    "from qiskit.circuit.library import RealAmplitudes #RealAmplitudes is a variational form that can be used as ansatz\n",
    "from qiskit_algorithms.optimizers import COBYLA #COBYLA is a classical optimizer\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from quantum import * #importing the functions from the quantum.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel modulo quantum.py sono definite le funzioni AnsatzeBuilder, SwaptestBuilder ed EncoderBuilder che restituiscono i corrispondenti circuiti quantistici (si veda file per dettagli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sez 2.1 Costruzione del Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si definiscono lo stato iniziale che si vuole comprimere (q), la dimensione dello stato compresso e la profondità del circuito parametrico RealAmplitudes associato all'encoder. Viene costruito l'encoder attraverso la funzione EncoderBuilder, che restituisce un circuito composto dal circuito parametrico RealAmplitudes seguito dal circuito che esegue lo SWAP test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametri\n",
    "q = [0,0,1,1,1,0,0,0,0,0] #input state\n",
    "EncodedStateDimension = 3\n",
    "Depth = 3\n",
    "\n",
    "#Costruisco encoder\n",
    "InputStateDimension = len(q)\n",
    "Encoder = EncoderBuilder(InputStateDimension, EncodedStateDimension, Depth)\n",
    "#Costruisco circuito generico, resetto qubit a 0 e applico X ai qubit 2,3,4\n",
    "Circuit = QuantumCircuit(Encoder.num_qubits, Encoder.num_clbits)\n",
    "for i in range(Circuit.num_qubits):\n",
    "    Circuit.reset(i)\n",
    "for i in range(InputStateDimension):\n",
    "    if q[i] == 1:\n",
    "        Circuit.x(i)\n",
    "Circuit.compose(Encoder, inplace=True)\n",
    "#Circuit.draw('mpl', filename='circuit.png')\n",
    "#Circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/circuit.png\" alt=\"Alt Text\" width=\"1000\">\n",
    "    <p><em>Figure 4: schema circuito completo. q = [0,0,1,1,1,0,0,0,0,0], EncodedStateDimension = 3, Depth = 3</em></p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sez 2.1.1 RealAmplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per implementare un encoder con un circuito quantistico è necessario definire l'operatore unitario $U(\\theta_i)$, in modo che il numero di gate (e quindi di parametri) scali in modo polinomiale rispetto al numero di qubit di input. Una delle possibilità è quella di impiegare un circuito \"modulare\", in cui un circuito \"modulo\" viene ripetuto un certo numero di volte (Depth del circuito). Abbiamo utilizzato un circuito 2-locale, che permettesse rotazione di ogni singolo qubit ad ogni layer e entanglement tra 2 qubit adiacenti. Un semplice circuito parametrico 2-locale già presente nella libreria qiskit è RealAmplitudes (Figura 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/schema_RealAmplitudes.png\" alt=\"Alt Text\" width=\"1000\">\n",
    "    <p><em>Figure 5: schema circuito RealAmplitudes. InputDimension = 5, Depth = 5</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sez2.1.2 SWAP TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per addestrare $U(\\theta_i)$ alla compressione degli stati, è necessario calcolare una funzione costo. Come descritto nella sezione 1.2 la funzione costo è misurata come la fedeltà del Trash Space al Reference Space, della stessa dimensione del precedente e composto da qubit nello stato |0>. Una volta applicato il circutio la fedeltà tra i due blocchi può essere misurata come la probabilità di misurare |0> sul qubit ancella. La funzione SwaptestBuilder ritorna il circuito di swap test con un operatore di misura sul qubit ancella verso un canale classico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/SWAP.png\" alt=\"Alt Text\" width=\"500\">\n",
    "    <p><em>Figure 6: schema circuito SWAPTEST con Trash Space dimension = 7</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sez 2.2 Addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/hybrid.png\" alt=\"Alt Text\" width=\"500\">\n",
    "    <p><em>Figure 7: Rappresentazione del sistema ibrido classico-quantistico per l'addestramento dell'autoencoder. Rif.[1]</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo definire la funzione costo come la probabilità di ottenere |1> sul qubit ancella. Questo dato classico può essere passato ad un ottimizzatore classico per il calcolo di un nuovo set di parametri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione di qiskit SamplerQNN funge da interfaccia tra il circuito parametrico costruito fin ora e il simulatore di qiskit (Aer). In particolare vengono passati alla funzione circuito, parametri da ottimizzare e parametri iniziali. Gli argomento interpreter e output_shape dipendono dal circuito che stiamo passando e dal simulatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interprete per SamplerQNN\n",
    "def identity_interpret(x):\n",
    "    return x\n",
    "\n",
    "qnn = SamplerQNN(\n",
    "    circuit=Circuit, #circuito completo\n",
    "    input_params=[], #guess iniziale lasciato a SamplerQNN, quindi randomici\n",
    "    weight_params=Circuit.parameters, #identificato i parametri del circuito, quindi i parametri di RealAmplitudes\n",
    "    interpret=identity_interpret,\n",
    "    output_shape=2, #l'output del circuito può essere 1 o 0, una stringa binaria di dimensione 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo cost_function che calcola la funzione costo dato un set di parametri in input. I parametri vengono passati al simulatore e otteniamo le nuove probabilità. Ogni valore di cost viene salvato in un array, che viene plottato ogni volta che la funzione viene chiamata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(params_values):\n",
    "    #calcolo probabilità passando i nuovi parametri\n",
    "    probabilities = qnn.forward([], params_values)\n",
    "    # probabilità di ottenere 1 come output della simulazione, cioè la funzione costo\n",
    "    cost = np.sum(probabilities[:, 1])\n",
    "\n",
    "    # plotting part\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(cost)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sez 2.2.1 COBYLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrained Optimization BY Linear Approximations è un algoritmo di ottimizzazione di ricerca diretta, per ricerca diretta si intende un metodo per risolvere problemi di ottimizzazione che non richiede alcuna informazione sul gradiente della funzione obiettivo. A differenza dei metodi di ottimizzazione più tradizionali che utilizzano gradienti o derivate di ordine superiore per cercare un punto ottimale, un algoritmo di ricerca diretta esplora un insieme di punti intorno al punto corrente, cercandone uno in cui il valore della funzione obiettivo sia inferiore rispetto al valore nel punto corrente.\n",
    "Quindi, COBYLA è in grado di risolvere problemi espressi nella forma:\n",
    "\n",
    "\\begin{cases}\n",
    "    \\text{Minimizzo } F(\\mathbf{x}), & \\mathbf{x} \\in \\mathbb{R}^n \\\\\n",
    "    \\text{soggetta a } c_i(\\mathbf{x}) \\geq 0, & i = 1, \\ldots, m\n",
    "\\end{cases}\n",
    "\n",
    "Per farlo si basa sull'idea dell'algortimo di Nelder e Mead di utilizzare dei simplessi non degeneri in $\\mathbb{R}^n$. Così facendo si può dire che esistono delle funzioni lineari uniche $\\hat{F}$ e $\\hat{c}_i$ che interpolano $F$ e $c_i$ ai vertici. Quindi, l'obiettivo originario viene approssimato da un problema di programmazione lineare:\n",
    "\n",
    "\\begin{cases}\n",
    "   \\text{minimizzo } \\hat{F}(\\mathbf{x}), & \\mathbf{x} \\in \\mathbb{R}^n \\\\\n",
    "   \\text{soggetta a } \\hat{c}_i(\\mathbf{x}) \\geq 0, & i = 1, \\ldots, m\n",
    "\\end{cases}\n",
    "\n",
    "\n",
    "Operativamente, l'algoritmo parte generando un set di punti $\\textbf{x}^{(j)}$, con $j = 0, ..., n$, i quali sono i vertici del simplesso, prende in input un valore $\\rho > 0$ che è il raggio di una regione di confidenza, questa si riferisce all'area in cui la funzione obiettivo viene approssimata da un modello più semplice, ed infine un $\\mu > 0$ che è il parametro di una funzione di merito per il confronto tra due $\\textbf{x}$.\n",
    "La funzione di merito è:\n",
    "\n",
    "$$\n",
    "\\Phi(\\textbf{x}) = F(\\textbf{x}) + \\mu \\left[ \\text{max}\\{ -c_i(\\textbf{x}):\\; i=1, ...,m \\} \\right]_+,\\; \\textbf{x} \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "questa funzione serve per determinare l'ottimalità di un punto $\\textbf{x}$ rispetto ad un altro, un vettore $i$ è migliore di un altro $j$ se e soltanto se $\\Phi(\\text{x}_i)<\\Phi(\\text{x}_j)$. Infatti un punto è tanto buono quanto rispetta i constraint del problema, se un punto non li rispetta avrà alcuni $c_i < 0$, per cui prendendo il massimo dei valori non rispettati, moltiplicato per un certo fattore $\\mu$, e sommandolo al valore originario della funzione, si penalizza quel determinato punto. Il pedice $+$ significa che la parentesi quadra viene messa a zero se tutti i constraint sono soddisfatti per quel punto.\n",
    "\n",
    "Una volta presi i punti iniziali, l'algoritmo li ordina per bontà, di modo che $\\Phi(\\textbf{x}^{(0)}) \\leq \\Phi(\\textbf{x}^{(j)})$ per $j = 1, ..., n$. Dopodiché, si trovano dei candidati $\\textbf{x}^{(*)}$ minimi della funzione, per farlo se possibile si risolve il sistema linearizzato controllando che sia rispettata la condizione:\n",
    "\n",
    "$$\n",
    "||\\textbf{x}^{(*)} - \\textbf{x}^{(0)}||_2 \\leq \\rho\n",
    "$$\n",
    "\n",
    "e i constraint:\n",
    "\n",
    "$$\n",
    "\\hat{c}_i(x^{(*)}) \\geq 0,\\; i = 1, ..., m\n",
    "$$\n",
    "\n",
    "se sono tutte verificate e ci sono più candidati, allora si prende il punto che dà il minimo valore di $||\\textbf{x}^{(*)} - \\textbf{x}^{(0)}||_2$.\n",
    "Può capitare che le due diseguaglianze siano in contraddizione, se ciò accade violando la seconda, si definisce $\\textbf{x}^{(*)}$ minimizzando le violazioni dei constraint lineari, tenendo conto della regione di confidenza. Se c'è ancora ambiguità, si guardano i valori di $\\hat{F}$ e si prende quello che li minimizza. E se a questo punto non c'è ancora una sola scelta, il candidato migliore è quello che minimizza $||\\textbf{x}^{(*)} - \\textbf{x}^{(0)}||_2$.\n",
    "\n",
    "Anche $\\mu$ varia e lo fa in base ai valori di $\\textbf{x}^{(*)}$. Inizialmente $\\mu$ è un valore positivo molto piccolo, ma un valore troppo vicino a zero potrebbe portare la condizione $\\hat{\\Phi}(\\textbf{x}^{(*)}) < \\hat{\\Phi}(\\textbf{x}^{(0)})$ a non essere verificata, dove le $\\hat{\\Phi}$ sono le stesse di prima ma con il problema linearizzato. Quindi, se $\\mu$ non è grande abbastanza va revisionato. Sia $\\bar{\\mu}$ il più piccolo valore di $\\mu$ non negativo che soddisfa $\\hat{\\Phi}(\\textbf{x}^{(*)}) < \\hat{\\Phi}(\\textbf{x}^{(0)})$, il valore rimane fisso se $\\mu > \\frac{3}{2}\\bar{\\mu}$, altrimenti $\\mu$ viene sostituito con $2\\hat{\\mu}$. $\\Phi(\\textbf{x}^{(0)}) \\leq \\Phi(\\textbf{x}^{(j)})$ per $j = 1, ..., n$ potrebbe non essere più verificato dopo l'aggiornamento di $\\mu$, se questo succede allora si scambiano coppie di vertici e si ricalcola $\\mu$ fino a quando la situazione diventa accettabile.\n",
    "\n",
    "Ora si vede come si aggiorna $\\rho$, innanzitutto questo valore o rimane invariato o viene ridotto, ma non può mai diventare più grande. L'aggiornamento avviene se\n",
    "\n",
    "$$||\\textbf{x}^{(*)} - \\textbf{x}^{(0)}||_2 < \\frac{1}{2}\\rho\n",
    "$$\n",
    "\n",
    "oppure,\n",
    "\n",
    "$$\\Phi(\\textbf{x}^{(0)}) - \\Phi(\\textbf{x}^{(*)}) < 0.1 \\left[ \\hat{\\Phi}(\\textbf{x}^{(0)}) - \\hat{\\Phi}(\\textbf{x}^{(*)}) \\right]$$\n",
    "\n",
    "questa seconda condizione significa che l'aggiornamento da $\\textbf{x}^{(0)}$ a $\\textbf{x}^{(*)}$ porterebbe a meno di un decimo del miglioramento predetto dall'approssimazione lineare.\n",
    "Il nuovo valore del raggio $\\rho_{\\text{new}}$ viene posto uguale a $\\frac{1}{2} \\rho$ se $\\rho > 3 \\rho_{\\text{end}}$, altrimenti $\\rho_{\\text{new}} = \\rho_{\\text{end}}$, dove $\\rho_{\\text{end}}$ è la precisione numerica che si vorrebbe ottenere sulla soluzione, ed è dato in input dall'utente, e quando questa viene raggiunta l'algoritmo si ferma.\n",
    "Una diminuzione della regione di confidenza potrebbe rendere il simplesso non accettabile, il simplesso è accettabile se\n",
    "\n",
    "\n",
    "\\begin{cases}\n",
    "   \\sigma^{(j)} \\geq \\alpha \\rho \\\\\n",
    "   \\eta^{(j)} \\geq \\beta \\rho\n",
    "\\end{cases}\n",
    "\n",
    "\n",
    "per $j = 1, ..., n$, e $\\alpha$ e $\\beta$ sono costanti scelta in modo da avere $0<\\alpha<1<\\beta$.\n",
    "\n",
    "Il simplesso iniziale viene scelto a partire da $\\rho_{\\text{beg}}$, che è il raggio iniziale della regione di confidenza, e da un punto $\\textbf{x}^{(0)}$, che a seconda delle implementazioni può essere dato in input dall'utente, oppure scelto a caso dal computer. Il simplesso dovrà avere $n+1$ vertici, quindi il programma cicla su $j = 0, ..., n$ e imposta $\\textbf{x}^{(j)} = \\textbf{x}^{(0)} + \\rho_{\\text{beg}} \\textbf{e}_j$, dove $\\textbf{e}_j$ è un vettore di dimensione $n$ con entrate $i \\neq j$ uguali a $0$, e $1$ in $i = j$, inoltre $\\textbf{x}^{(0)}$ viene scambiato con $\\textbf{x}^{(j)}$ se e soltanto se $F(\\textbf{x}^{(j)}) < F(\\textbf{x}^{(0)})$. Il primo simplesso non deve rispettare le condizioni di accettabilità.\n",
    "\n",
    "Il vettore $\\textbf{x}^{(*)}$ non è calcolato ad ogni iterazione, talvolta è preferibile dare priorità alla costruzione di un simplesso accettabile e quindi calcolare un altro punto $\\textbf{x}^{(\\Delta)}$.\n",
    "\n",
    "$\\textbf{x}^{(*)}$ viene calcolato se una di queste condizioni è soddisfatta: è la prima iterazione. L'iterazione precedente ha ridotto $\\rho$. L'iterazione precedente ha calcolato $\\textbf{x}^{(\\Delta)}$. L'iterazione precedente ha calcolato $\\textbf{x}^{(*)}$ e ha ridotto la funzione di merito almeno di un decimo del valore aspettato. Il simplesso attuale è accettabile.\n",
    "$\\textbf{x}^{(\\Delta)}$ è definito come segue: se un qualsiasi valore $\\eta^{(j)}$ è maggiore di $\\beta \\rho$, allora definiamo $l$ come l'intero più piccolo tra gli indici $1, ..., n$ che soddisfa l'equazione:\n",
    "$$\n",
    "\\eta^{(l)} = \\max \\{ \\eta^{(j)}:\\; j=1, ...,n \\} \n",
    "$$\n",
    "\n",
    "altrimenti:\n",
    "\n",
    "$$\n",
    "\\sigma^{(l)} = \\min \\{ \\sigma^{(j)}:\\; j=1, ...,n \\} \n",
    "$$\n",
    "\n",
    "Si prende $\\textbf{v}^{(l)}$, vettore unitario perpendicolare alla faccia opposta al vertice che verrà sostituito, perciò:\n",
    "\n",
    "$$\n",
    "\\textbf{x}^{(\\Delta)} = \\textbf{x}^{(0)} \\pm \\gamma \\rho \\textbf{v}^{(l)}\n",
    "$$\n",
    "\n",
    "dove $\\pm$ indica che si sceglierà il segno dell'operazione in base a quella che minimizza $\\hat{\\Phi}(\\textbf{x}^{(\\Delta)})$\\, e $\\gamma$ è una costante compresa tra $\\alpha$ ed $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sez. 2.3 Risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo a questo punto addestrato l'encoder con i parametri fissati nella sezione 2.1 su 300 iterazioni di COBYLA plottando la loss ad ogni iterazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "# Initialize the COBYLA optimizer\n",
    "opt = COBYLA(maxiter=300)\n",
    "num_parameters = Circuit.num_parameters\n",
    "initial_point = np.random.rand(num_parameters)  # Set the initial parameters\n",
    "print('Number of parameters in quantum circuit: ',Circuit.num_parameters)\n",
    "print('Initial parameters in quantum circuit: ',initial_point)\n",
    "\n",
    "# Perform optimization\n",
    "start = time.time()\n",
    "opt_result = opt.minimize(cost_function,initial_point)\n",
    "#print('Cost function value:', cost_function(initial_point))\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Fit in {elapsed:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./immagini/plot_loss-time.png\" alt=\"Alt Text\" width=\"500\">\n",
    "    <p><em>Figure 8: plot loss-time.</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sezione 3 Caratterizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]  Jonathan Romero, Jonathan P. Olson and Alan Aspuru-Guzik, \"Quantum autoencoders for efficient compression of quantum data\", Quantum Science and Technology, 2017\n",
    "\n",
    "[2] Qiskit machine learning tutorials, \"The quantum autoencoder\", https://qiskit.org/ecosystem/machine-learning/tutorials/12_quantum_autoencoder.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
